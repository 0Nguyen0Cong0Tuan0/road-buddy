{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0Nguyen0Cong0Tuan0/Road-Buddy-Challenge/blob/main/models/yolo_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title-section"
      },
      "source": [
        "# **YOLO11 Fine-tuning for Traffic Object Detection**\n",
        "\n",
        "\n",
        "This notebook **fine-tunes YOLO11n and YOLO11l** on custom traffic datasets to improve detection of **road objects** such as cars, trucks, buses, lanes, traffic lights, road signs and **exclude unrelated** such as toothbrush, skis, wine glass, etc.\n",
        "\n",
        "\n",
        "\n",
        "**Datasets**\n",
        "\n",
        "| Dataset | Classes | Focus |\n",
        "|---------|---------|-------|\n",
        "| BDD100K | 12 | Vehicles, pedestrians, traffic signs/lights |\n",
        "| Road Lane v2 | 6 | Lane line types (dotted, solid, divider, etc.) |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHXtP5CTgnPf",
        "outputId": "143696ca-a27e-47d7-9fd3-4fa7ceb85bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-ultralytics"
      },
      "outputs": [],
      "source": [
        "# Install Ultralytics (YOLO)\n",
        "!pip install ultralytics -q\n",
        "\n",
        "# Verify installation\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "print(f\"\\n‚úÖ Ultralytics version: {ultralytics.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount-drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "\n",
        "print(\"‚úÖ All imports ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paths-section"
      },
      "source": [
        "## 2. Define Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define-paths"
      },
      "outputs": [],
      "source": [
        "# Dataset paths on Google Drive\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/traffic datasets/Kaggle Datasets\"\n",
        "\n",
        "# Dataset 1: Road Lane Segmentation (for lane detection)\n",
        "LANE_DATASET_PATH = f\"{DRIVE_BASE}/road-lane-segmentation\"\n",
        "\n",
        "# Dataset 2: BDD100K (for general traffic object detection)\n",
        "BDD100K_PATH = f\"{DRIVE_BASE}/bdd100k\"\n",
        "\n",
        "# Working directory\n",
        "WORK_DIR = \"/content/yolo_training\"\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "\n",
        "print(\"üìÅ Dataset Paths:\")\n",
        "print(f\"   Lane Dataset: {LANE_DATASET_PATH}\")\n",
        "print(f\"   BDD100K: {BDD100K_PATH}\")\n",
        "print(f\"   Working Dir: {WORK_DIR}\")\n",
        "\n",
        "# Verify datasets exist\n",
        "print(\"\\nüîç Verifying datasets...\")\n",
        "print(f\"   Lane Dataset exists: {os.path.exists(LANE_DATASET_PATH)}\")\n",
        "print(f\"   BDD100K exists: {os.path.exists(BDD100K_PATH)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore-lane-dataset"
      },
      "outputs": [],
      "source": [
        "# Explore Lane Dataset structure\n",
        "print(\"üìÇ Lane Dataset Structure:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def show_dir_structure(path, indent=0):\n",
        "    \"\"\"Show directory structure.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"{'  ' * indent}‚ùå Path not found: {path}\")\n",
        "        return\n",
        "\n",
        "    items = sorted(os.listdir(path))\n",
        "    for item in items[:15]:  # Limit to 15 items\n",
        "        item_path = os.path.join(path, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            count = len(os.listdir(item_path))\n",
        "            print(f\"{'  ' * indent}üìÅ {item}/ ({count} items)\")\n",
        "            if indent < 2:  # Only go 2 levels deep\n",
        "                show_dir_structure(item_path, indent + 1)\n",
        "        else:\n",
        "            print(f\"{'  ' * indent}üìÑ {item}\")\n",
        "\n",
        "show_dir_structure(LANE_DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-yaml-section"
      },
      "source": [
        "## 3. Create/Fix data.yaml for YOLO Training\n",
        "\n",
        "YOLO requires a `data.yaml` file with correct paths to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create-lane-yaml"
      },
      "outputs": [],
      "source": [
        "# Create data.yaml for Road Lane Segmentation Dataset\n",
        "# This dataset has 1 class: Lane\n",
        "\n",
        "lane_data_yaml = {\n",
        "    'path': f\"{LANE_DATASET_PATH}/dataset\",  # Dataset root directory\n",
        "    'train': 'train/images',  # Train images (relative to path)\n",
        "    'val': 'val/images',      # Validation images (relative to path)\n",
        "    'test': 'test/images',    # Test images (relative to path)\n",
        "    'nc': 1,                  # Number of classes\n",
        "    'names': ['Lane']         # Class names\n",
        "}\n",
        "\n",
        "# Save to working directory\n",
        "lane_yaml_path = f\"{WORK_DIR}/lane_data.yaml\"\n",
        "with open(lane_yaml_path, 'w') as f:\n",
        "    yaml.dump(lane_data_yaml, f, default_flow_style=False)\n",
        "\n",
        "print(\"‚úÖ Created lane_data.yaml:\")\n",
        "print(\"=\" * 50)\n",
        "with open(lane_yaml_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Verify paths exist\n",
        "print(\"\\nüîç Verifying paths...\")\n",
        "dataset_root = lane_data_yaml['path']\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(dataset_root, lane_data_yaml[split])\n",
        "    exists = os.path.exists(split_path)\n",
        "    count = len(os.listdir(split_path)) if exists else 0\n",
        "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "    print(f\"   {status} {split}: {split_path} ({count} files)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-section"
      },
      "source": [
        "## 4. Load YOLO11 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-model"
      },
      "outputs": [],
      "source": [
        "# Load YOLO11n (nano) model - smallest and fastest\n",
        "# Options: yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt\n",
        "\n",
        "model = YOLO('yolo11n.pt')  # This will download if not present\n",
        "\n",
        "print(\"\\n‚úÖ YOLO11n model loaded!\")\n",
        "print(f\"   Model type: {model.task}\")\n",
        "print(f\"   Model info: {model.info()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training-section"
      },
      "source": [
        "## 5. Train the Model\n",
        "\n",
        "‚ö†Ô∏è **Important**: Make sure you have GPU enabled!\n",
        "- Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `T4 GPU`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-gpu"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "print(\"üñ•Ô∏è Hardware Check:\")\n",
        "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è No GPU detected! Training will be slow.\")\n",
        "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí Select T4 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train-lane-model"
      },
      "outputs": [],
      "source": [
        "# Training Configuration for Lane Detection\n",
        "TRAIN_CONFIG = {\n",
        "    'data': lane_yaml_path,      # Path to data.yaml\n",
        "    'epochs': 50,                # Number of training epochs\n",
        "    'imgsz': 640,                # Image size\n",
        "    'batch': 16,                 # Batch size (reduce if OOM error)\n",
        "    'patience': 10,              # Early stopping patience\n",
        "    'save': True,                # Save checkpoints\n",
        "    'project': f'{WORK_DIR}/runs',  # Save results here\n",
        "    'name': 'lane_detection',    # Experiment name\n",
        "    'exist_ok': True,            # Overwrite existing experiment\n",
        "    'pretrained': True,          # Use pretrained weights\n",
        "    'optimizer': 'auto',         # Optimizer (auto, SGD, Adam, AdamW)\n",
        "    'verbose': True,             # Verbose output\n",
        "    'seed': 42,                  # Random seed for reproducibility\n",
        "}\n",
        "\n",
        "print(\"üöÄ Training Configuration:\")\n",
        "for key, value in TRAIN_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start-training"
      },
      "outputs": [],
      "source": [
        "# Start Training!\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results = model.train(**TRAIN_CONFIG)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluate-section"
      },
      "source": [
        "## 6. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validate-model"
      },
      "outputs": [],
      "source": [
        "# Validate on test set\n",
        "print(\"üìä Validating on test set...\")\n",
        "\n",
        "# Load the best model\n",
        "best_model_path = f\"{WORK_DIR}/runs/lane_detection/weights/best.pt\"\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "# Run validation\n",
        "metrics = best_model.val(data=lane_yaml_path, split='test')\n",
        "\n",
        "print(\"\\nüìà Test Results:\")\n",
        "print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"   mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"   Recall: {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualize-results"
      },
      "outputs": [],
      "source": [
        "# Visualize training results\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "results_dir = f\"{WORK_DIR}/runs/lane_detection\"\n",
        "\n",
        "# Display training curves\n",
        "print(\"üìä Training Results:\")\n",
        "result_images = ['results.png', 'confusion_matrix.png', 'F1_curve.png', 'PR_curve.png']\n",
        "\n",
        "for img_name in result_images:\n",
        "    img_path = f\"{results_dir}/{img_name}\"\n",
        "    if os.path.exists(img_path):\n",
        "        print(f\"\\n{img_name}:\")\n",
        "        display(Image(filename=img_path, width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inference-section"
      },
      "source": [
        "## 7. Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test-inference"
      },
      "outputs": [],
      "source": [
        "# Test inference on sample images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Get sample test images\n",
        "test_images_dir = f\"{LANE_DATASET_PATH}/dataset/test/images\"\n",
        "test_images = sorted(os.listdir(test_images_dir))[:6]  # First 6 images\n",
        "\n",
        "print(f\"üîç Running inference on {len(test_images)} sample images...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, img_name in enumerate(test_images):\n",
        "    img_path = os.path.join(test_images_dir, img_name)\n",
        "\n",
        "    # Run inference\n",
        "    results = best_model.predict(img_path, conf=0.25, verbose=False)\n",
        "\n",
        "    # Get annotated image\n",
        "    annotated = results[0].plot()\n",
        "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    axes[idx].imshow(annotated)\n",
        "    axes[idx].set_title(img_name[:30])\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle('Lane Detection Results', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save-section"
      },
      "source": [
        "## 8. Save Model to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-model"
      },
      "outputs": [],
      "source": [
        "# Save trained model to Google Drive\n",
        "SAVE_DIR = \"/content/drive/MyDrive/traffic datasets/trained_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Copy best and last weights\n",
        "weights_dir = f\"{WORK_DIR}/runs/lane_detection/weights\"\n",
        "\n",
        "for weight_file in ['best.pt', 'last.pt']:\n",
        "    src = f\"{weights_dir}/{weight_file}\"\n",
        "    dst = f\"{SAVE_DIR}/lane_detection_{weight_file}\"\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "        print(f\"‚úÖ Saved: {dst}\")\n",
        "\n",
        "# Copy training results\n",
        "results_dst = f\"{SAVE_DIR}/lane_detection_results\"\n",
        "if os.path.exists(results_dir):\n",
        "    shutil.copytree(results_dir, results_dst, dirs_exist_ok=True)\n",
        "    print(f\"‚úÖ Saved training results to: {results_dst}\")\n",
        "\n",
        "print(\"\\n‚úÖ All models saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export-section"
      },
      "source": [
        "## 9. Export Model (Optional)\n",
        "\n",
        "Export to different formats for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export-model"
      },
      "outputs": [],
      "source": [
        "# Export model to ONNX format (optional)\n",
        "# Uncomment to export\n",
        "\n",
        "# print(\"üì¶ Exporting model to ONNX...\")\n",
        "# best_model.export(format='onnx')\n",
        "# print(\"‚úÖ Model exported to ONNX format!\")\n",
        "\n",
        "# Available export formats:\n",
        "# - onnx: ONNX format\n",
        "# - torchscript: TorchScript\n",
        "# - coreml: CoreML (iOS)\n",
        "# - tflite: TensorFlow Lite (mobile)\n",
        "# - engine: TensorRT (NVIDIA GPU)\n",
        "\n",
        "print(\"üí° To export, uncomment the export code above.\")\n",
        "print(\"   Available formats: onnx, torchscript, coreml, tflite, engine\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary-section"
      },
      "source": [
        "## üìã Summary\n",
        "\n",
        "This notebook trained a YOLO11 model for **lane detection**.\n",
        "\n",
        "### Files Saved:\n",
        "- `lane_detection_best.pt` - Best model weights\n",
        "- `lane_detection_last.pt` - Last checkpoint\n",
        "- `lane_detection_results/` - Training curves and metrics\n",
        "\n",
        "### Next Steps:\n",
        "1. Download the model from Google Drive\n",
        "2. Use for inference in your application\n",
        "3. Fine-tune with more data if needed"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
